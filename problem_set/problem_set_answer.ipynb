{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85fefe6-e3e9-44b2-9bdc-fc03d30080b6",
   "metadata": {},
   "source": [
    "# LoRA on MNIST  \n",
    "1. Build an MLP. Train this model to perform well on MNIST 0-4 (half of the data).\n",
    "3. Use standard finetuning approach to train this model to work on MNIST 5-9 (this will act as our baseline)\n",
    "4. Use LoRA finetuning to train the original model to work on MNIST 5-9\n",
    "5. Compare finetuning techniques (performance, memory etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e02a5d-8dd2-4361-b7cf-9d33b025a410",
   "metadata": {},
   "source": [
    "Sources:\n",
    "1. https://arxiv.org/abs/2106.09685 - LoRA paper\n",
    "2. https://lightning.ai/pages/community/tutorial/lora-llm/ - (The first half offers useful starter pseudocode)\n",
    "3. https://colab.research.google.com/drive/1iERDk94Jp0UErsPf7vXyPKeiM4ZJUQ-a?usp=sharing#scrollTo=WuK0lPwcB7Ia - had some good ideas on metrics to compute about LoRA-ized model\n",
    "4. https://lightning.ai/docs/pytorch/stable/notebooks/lightning_examples/mnist-hello-world.html - starter code for building an MLP and training on MNIST\n",
    "5. https://discuss.pytorch.org/t/how-to-use-one-class-of-number-in-mnist/26276/21 - forum post on how to limit MNIST to only first or second half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423b1158-1d05-4a05-b5b2-f5a0edc9ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import LearningRateFinder\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from pytorch_lightning import Callback\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set precision to what lightning suggests for this gpu\n",
    "torch.set_float32_matmul_precision('high')\n",
    "# make results reproducible\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fd83ca-88db-4682-85e1-904d4f5df759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserved for constants\n",
    "PATH_DATASETS = 'data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d712261-bb19-459d-8272-b33e529bc613",
   "metadata": {},
   "source": [
    "Train an MLP on the first half of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27414d79-396d-460d-8700-aee7169c20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(L.LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, lr=2e-4):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.data_dir = data_dir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # Hardcode some dataset specific attributes\n",
    "        self.class_names = [0,1,2,3,4]\n",
    "        self.min_class = min(self.class_names)\n",
    "        self.num_classes = len(self.class_names) \n",
    "        self.dims = (1, 28, 28) # the shape of an example (C x W x H)\n",
    "        channels, width, height = self.dims\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.batch_size = 1024\n",
    "\n",
    "        # Define layers for model\n",
    "        self.l1 = nn.Linear(channels * width * height, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, self.num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "        # Define metrics\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # preprocessing\n",
    "        x = torch.flatten(x,1)\n",
    "\n",
    "        # layer 1 (input size, hidden size)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # layer 2 (hidden size, hidden size)\n",
    "        x = self.l2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #layer 3 (hidden size, self.num_classes)\n",
    "        x = self.l3(x)\n",
    "                    \n",
    "        # notice that we return the log probabilities here as that is what nll loss expects in the training step\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def common_step(self, batch, batch_idx):\n",
    "        # define steps all of {train, val, test} will take in one place\n",
    "        x, y = batch\n",
    "        # rescale y to be 0 indexed if necessary (like when we start using mnist 5-9)\n",
    "        if self.min_class != 0:\n",
    "            y = y - self.min_class\n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return x,y, logits, loss\n",
    "        \n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, _, _, loss = self.common_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # we'll use adamw to match the paper\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    # the rest of the class is helper functions/hooks for configuring data/dataloader building\n",
    "    @staticmethod\n",
    "    def get_indices(dataset,class_names):\n",
    "        if isinstance(dataset, torch.utils.data.dataset.Subset):\n",
    "            targets = torch.tensor([dataset.dataset.targets[i] for i in dataset.indices])\n",
    "        else:\n",
    "            targets = dataset.targets\n",
    "\n",
    "            \n",
    "        indices =  []\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i] in class_names:\n",
    "                indices.append(i)\n",
    "        return indices\n",
    "        \n",
    "    def create_dataloader(self,dataset):\n",
    "        idx = self.get_indices(dataset, self.class_names)\n",
    "        loader = DataLoader(dataset,batch_size=self.batch_size, sampler = SubsetRandomSampler(idx), num_workers=16) # Note - this necessarily shuffles the data due to the sampler we are using\n",
    "        return loader\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download data\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "            \n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_train)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_val)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_test)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcea2f7d-cb12-44df-96b0-e832632e905f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type               | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K | train\n",
      "1 | l2            | Linear             | 4.2 K  | train\n",
      "2 | l3            | Linear             | 325    | train\n",
      "3 | dropout       | Dropout            | 0      | train\n",
      "4 | relu          | ReLU               | 0      | train\n",
      "5 | val_accuracy  | MulticlassAccuracy | 0      | train\n",
      "6 | test_accuracy | MulticlassAccuracy | 0      | train\n",
      "-------------------------------------------------------------\n",
      "54.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "54.7 K    Total params\n",
      "0.219     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 28/28 [00:24<00:00,  1.14it/s, v_num=1, val_loss=0.112, val_acc=0.967]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 28/28 [00:24<00:00,  1.14it/s, v_num=1, val_loss=0.112, val_acc=0.967]\n"
     ]
    }
   ],
   "source": [
    "model = LitMNIST()\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=10,\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa45d80a-ea43-41a5-a8f4-a60ac95717bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.758767</td>\n",
       "      <td>1.072168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.644961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.925241</td>\n",
       "      <td>0.501563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939884</td>\n",
       "      <td>0.255306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.216880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_loss   val_acc  val_loss\n",
       "epoch                                \n",
       "0             NaN  0.758767  1.072168\n",
       "1        0.644961       NaN       NaN\n",
       "1             NaN  0.925241  0.501563\n",
       "2             NaN  0.939884  0.255306\n",
       "3        0.216880       NaN       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x32878a460>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 616.125x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "del metrics[\"step\"]\n",
    "metrics.set_index(\"epoch\", inplace=True)\n",
    "display(metrics.dropna(axis=1, how=\"all\").head())\n",
    "sn.relplot(data=metrics, kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6dc1512-5f6d-46a3-8129-1cea54a92aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at logs/lightning_logs/version_1/checkpoints/epoch=9-step=280.ckpt\n",
      "Loaded model weights from the checkpoint at logs/lightning_logs/version_1/checkpoints/epoch=9-step=280.ckpt\n",
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 6/6 [00:02<00:00,  2.01it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9735357165336609\n",
      "        test_loss           0.08790729194879532\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.08790729194879532, 'test_acc': 0.9735357165336609}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as expected our model performs well\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46379ebe-33f9-468a-a833-4dfefc489f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights so we can finetune from them later\n",
    "trainer.save_checkpoint(\"./model.ckpt\")\n",
    "torch.save(model.state_dict(), './model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a1f3b-6fe5-4839-b8d3-92f177c86ecb",
   "metadata": {},
   "source": [
    "# Finetune on second half of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c2a53b7-4004-43fb-87a3-c5129bb38746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model - we refer to it as \"no training\" as we are going to use this initialization to show that the model performs poorly on the second half of mnist (as it wasn't trained on it)\n",
    "model_loaded_no_training = LitMNIST.load_from_checkpoint(checkpoint_path=\"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05702f82-da58-46c3-a3d7-1b985b167e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set it up to run on the second half of mnist (digits 5,6,7,8,9)\n",
    "model_loaded_no_training.class_names= [5,6,7,8,9]\n",
    "model_loaded_no_training.min_class = min(model_loaded_no_training.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0b47dc5-e317-4fda-863a-e33013804f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type               | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K | train\n",
      "1 | l2            | Linear             | 4.2 K  | train\n",
      "2 | l3            | Linear             | 325    | train\n",
      "3 | dropout       | Dropout            | 0      | train\n",
      "4 | relu          | ReLU               | 0      | train\n",
      "5 | val_accuracy  | MulticlassAccuracy | 0      | train\n",
      "6 | test_accuracy | MulticlassAccuracy | 0      | train\n",
      "-------------------------------------------------------------\n",
      "54.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "54.7 K    Total params\n",
      "0.219     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/26957 [00:10<76:16:09,  0.10it/s, v_num=2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/26957 [00:10<76:22:25,  0.10it/s, v_num=2]\n"
     ]
    }
   ],
   "source": [
    "# we will train on the new data on exactly one element once (this is so we can access the trainer2.test() function, which allows us to easily evaluate how well our model works on the new data prior to training)\n",
    "model_loaded_no_training.batch_size = 1\n",
    "trainer_no_train = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_steps=1,\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")\n",
    "trainer_no_train.fit(model_loaded_no_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7e6c74d-ca4a-4ca9-94c0-22e7ecaa8d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at logs/lightning_logs/version_2/checkpoints/epoch=0-step=1.ckpt\n",
      "Loaded model weights from the checkpoint at logs/lightning_logs/version_2/checkpoints/epoch=0-step=1.ckpt\n",
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4861/4861 [00:22<00:00, 219.09it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.3462250530719757\n",
      "        test_loss           2.7943942546844482\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 2.7943942546844482, 'test_acc': 0.3462250530719757}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see our model performs extremely poorly on the new data that it hasn't seen, which is unsuprising. \n",
    "trainer_no_train.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "336a997e-8ec7-42be-ae7c-d2646899222e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type               | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K | train\n",
      "1 | l2            | Linear             | 4.2 K  | train\n",
      "2 | l3            | Linear             | 325    | train\n",
      "3 | dropout       | Dropout            | 0      | train\n",
      "4 | relu          | ReLU               | 0      | train\n",
      "5 | val_accuracy  | MulticlassAccuracy | 0      | train\n",
      "6 | test_accuracy | MulticlassAccuracy | 0      | train\n",
      "-------------------------------------------------------------\n",
      "54.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "54.7 K    Total params\n",
      "0.219     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (28) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 28/28 [00:27<00:00,  1.04it/s, v_num=3, val_loss=0.0728, val_acc=0.977]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 28/28 [00:27<00:00,  1.04it/s, v_num=3, val_loss=0.0728, val_acc=0.977]\n"
     ]
    }
   ],
   "source": [
    "# now finetune e2e on the new data\n",
    "model_5_9 = LitMNIST.load_from_checkpoint(checkpoint_path=\"model.ckpt\")\n",
    "# set it up to run on the second half of mnist (digits 5,6,7,8,9)\n",
    "model_loaded_no_training.class_names= [5,6,7,8,9]\n",
    "model_loaded_no_training.min_class = min(model_loaded_no_training.class_names)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=10,\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")\n",
    "trainer.fit(model_5_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fd0c776-ced6-48d2-bfc2-ebc5fb873ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at logs/lightning_logs/version_3/checkpoints/epoch=9-step=280.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at logs/lightning_logs/version_3/checkpoints/epoch=9-step=280.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|███████████████████████| 6/6 [00:00<00:00, 37.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9844327569007874     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.053532421588897705    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9844327569007874    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.053532421588897705   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.053532421588897705, 'test_acc': 0.9844327569007874}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unsuprisingly finetuning allows us to perform equally well on the second half of MNIST. However this approach would require us to save the ENTIRE model binary for each dataset we wanted to finetune our initial model on, which doesn't scale well.\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c4c1e-8141-4416-a0a1-1f8e596abd17",
   "metadata": {},
   "source": [
    "# Finetune on second half of MNIST using LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27563e84-9d50-480c-9202-91d7b5ec518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNISTLoRA(L.LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, lr=2e-4, lora_rank = 8):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.data_dir = data_dir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # Hardcode some dataset specific attributes\n",
    "        self.class_names = [0,1,2,3,4]\n",
    "        self.min_class = min(self.class_names)\n",
    "        self.num_classes = len(self.class_names) \n",
    "        self.dims = (1, 28, 28) # the shape of an example (C x W x H)\n",
    "        channels, width, height = self.dims\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        # Define layers for model\n",
    "        self.l1 = nn.Linear(channels * width * height, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, self.num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Define lora hyperparameters\n",
    "        self.lora_rank = lora_rank # The rank 'r' for the low-rank adaptation\n",
    "        self.lora_alpha = 1 # lora scaling factor\n",
    "        \n",
    "        # layer 1 lora layers\n",
    "        self.l1_lora_A = nn.Parameter(torch.empty(channels * width * height, self.lora_rank))\n",
    "        self.l1_lora_B = nn.Parameter(torch.empty(self.lora_rank, hidden_size))\n",
    "\n",
    "        # layer 2 lora layers\n",
    "        self.l2_lora_A =  nn.Parameter(torch.empty(hidden_size, self.lora_rank))\n",
    "        self.l2_lora_B = nn.Parameter(torch.empty(self.lora_rank, hidden_size))\n",
    "\n",
    "        # layer 3 lora layers\n",
    "        self.l3_lora_A = nn.Parameter(torch.empty(hidden_size, self.lora_rank))\n",
    "        self.l3_lora_B = nn.Parameter(torch.empty(self.lora_rank, self.num_classes))\n",
    "        \n",
    "        # Define initialization for lora layers (this ensures that the model behavior is identital to to the original model prior to finetuning)\n",
    "        for n,p in self.named_parameters():\n",
    "            if 'lora' in n:\n",
    "                if n[-1]=='A':\n",
    "                    nn.init.kaiming_uniform_(p, a=math.sqrt(5))\n",
    "                elif n[-1]=='B':\n",
    "                    nn.init.zeros_(p)\n",
    "\n",
    "        # freeze non lora weights\n",
    "        for n,p in self.named_parameters():\n",
    "            if 'lora' not in n:\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        # Define metrics\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "\n",
    "    def lora_linear(self, x, layer, lora_A, lora_B):\n",
    "        # does the work of combining outputs from normal layer and lora layer for x\n",
    "        # notice that h is the sum of two separate operations on x\n",
    "        h = layer(x)\n",
    "        h += x@(lora_A @ lora_B)*self.lora_alpha\n",
    "        return h\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # preprocessing\n",
    "        x = torch.flatten(x,1)\n",
    "        \n",
    "        # layer 1 (input size, hidden size)\n",
    "        x = self.lora_linear(x, self.l1, self.l1_lora_A, self.l1_lora_B)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # layer 2 (hidden size, hidden size)\n",
    "        x = self.lora_linear(x, self.l2, self.l2_lora_A, self.l2_lora_B)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #layer 3 (hidden size, self.num_classes)\n",
    "        x = self.lora_linear(x, self.l3, self.l3_lora_A, self.l3_lora_B)\n",
    "                    \n",
    "        # notice that we return the log probabilities here as that is what nll loss expects in the training step\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def common_step(self, batch, batch_idx):\n",
    "        # define steps all of {train, val, test} will take in one place\n",
    "        x, y = batch\n",
    "        # rescale y to be 0 indexed if necessary (like when we start using mnist 5-9)\n",
    "        if self.min_class != 0:\n",
    "            y = y - self.min_class\n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return x,y, logits, loss\n",
    "        \n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, _, _, loss = self.common_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=False)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # we'll use adamw to match the paper\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "\n",
    "        return {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"lr_scheduler\": {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "            \"frequency\": 1\n",
    "        },\n",
    "        }\n",
    "\n",
    "      \n",
    "    # the rest of the class is helper functions/hooks for configuring data/dataloader building\n",
    "    @staticmethod\n",
    "    def get_indices(dataset,class_names):\n",
    "        if isinstance(dataset, torch.utils.data.dataset.Subset):\n",
    "            targets = torch.tensor([dataset.dataset.targets[i] for i in dataset.indices])\n",
    "        else:\n",
    "            targets = dataset.targets\n",
    "\n",
    "            \n",
    "        indices =  []\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i] in class_names:\n",
    "                indices.append(i)\n",
    "        return indices\n",
    "        \n",
    "    def create_dataloader(self,dataset):\n",
    "        idx = self.get_indices(dataset, self.class_names)\n",
    "        loader = DataLoader(dataset,batch_size=self.batch_size, sampler = SubsetRandomSampler(idx), num_workers=16) # Note - this necessarily shuffles the data due to the sampler we are using\n",
    "        return loader\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download data\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_train)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_val)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44986317-f1ec-4b53-b68d-47b0db656ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try lora finetuning with different lora ranks\n",
    "def lora_experiment(rank):\n",
    "    state_dict = torch.load(\"model.pt\")\n",
    "    model = LitMNISTLoRA(lora_rank=rank,)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.class_names= [5,6,7,8,9]\n",
    "    model.min_class = min(model.class_names)\n",
    "    \n",
    "    from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=10,\n",
    "        callbacks=[lr_monitor, EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)],\n",
    "\n",
    "        enable_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model)\n",
    "    return trainer.test()[0]['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6dcee69-a9c7-4bb9-80a9-2bb5d8747cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type               | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K | train\n",
      "1 | l2            | Linear             | 4.2 K  | train\n",
      "2 | l3            | Linear             | 325    | train\n",
      "3 | dropout       | Dropout            | 0      | train\n",
      "4 | relu          | ReLU               | 0      | train\n",
      "5 | val_accuracy  | MulticlassAccuracy | 0      | train\n",
      "6 | test_accuracy | MulticlassAccuracy | 0      | train\n",
      "  | other params  | n/a                | 8.4 K  | n/a  \n",
      "-------------------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "54.7 K    Non-trainable params\n",
      "63.1 K    Total params\n",
      "0.252     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 422/422 [00:33<00:00, 12.71it/s, v_num=3, val_acc=0.953] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 422/422 [00:33<00:00, 12.70it/s, v_num=3, val_acc=0.953]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /Users/keruiwu/Documents/RPI/ML&Opt/lightning_logs/version_3/checkpoints/epoch=9-step=4220.ckpt\n",
      "Loaded model weights from the checkpoint at /Users/keruiwu/Documents/RPI/ML&Opt/lightning_logs/version_3/checkpoints/epoch=9-step=4220.ckpt\n",
      "/Users/keruiwu/anaconda3/envs/cpd/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 76/76 [00:01<00:00, 54.26it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9491873979568481\n",
      "        test_loss           0.15563635528087616\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type               | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K | train\n",
      "1 | l2            | Linear             | 4.2 K  | train\n",
      "2 | l3            | Linear             | 325    | train\n",
      "3 | dropout       | Dropout            | 0      | train\n",
      "4 | relu          | ReLU               | 0      | train\n",
      "5 | val_accuracy  | MulticlassAccuracy | 0      | train\n",
      "6 | test_accuracy | MulticlassAccuracy | 0      | train\n",
      "  | other params  | n/a                | 16.7 K | n/a  \n",
      "-------------------------------------------------------------\n",
      "16.7 K    Trainable params\n",
      "54.7 K    Non-trainable params\n",
      "71.4 K    Total params\n",
      "0.286     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{8: 0.9491873979568481}\n",
      "Epoch 9: 100%|██████████| 422/422 [00:34<00:00, 12.20it/s, v_num=4, val_acc=0.958]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 422/422 [00:34<00:00, 12.19it/s, v_num=4, val_acc=0.958]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/keruiwu/Documents/RPI/ML&Opt/lightning_logs/version_4/checkpoints/epoch=9-step=4220.ckpt\n",
      "Loaded model weights from the checkpoint at /Users/keruiwu/Documents/RPI/ML&Opt/lightning_logs/version_4/checkpoints/epoch=9-step=4220.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 76/76 [00:01<00:00, 70.26it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9561818838119507\n",
      "        test_loss           0.13809379935264587\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "{8: 0.9491873979568481, 16: 0.9561818838119507}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for rank in [8, 16]:\n",
    "    result = lora_experiment(rank)\n",
    "    results[rank] = result\n",
    "    print(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b7229c",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9458be-b334-4da8-be94-c42b36c72f01",
   "metadata": {},
   "source": [
    "| Model                      | Approx. Number of Trainable Parameters | Percent Trainable Parameters Relative to Baseline | Test Accuracy            |\n",
    "|----------------------------|----------------------------------------|--------------------------------------------------|---------------------------|\n",
    "| Baseline - Whole Model Finetune | 54,700                                | 1.00                                           | 0.9844327569007874                        |\n",
    "| LoRA Rank = 8              | 8,400                                  | 15.36%                                           | 0.949                      |\n",
    "| LoRA Rank = 16             | 16,700                                 | 30.53%                                           | 0.956                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775a336",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
